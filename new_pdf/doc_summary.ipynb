{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f853129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (0.10.20)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.2.0,>=0.1.4 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.1.9)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.20 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.10.20.post2)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.5 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.1.11)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2024.3.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.25.2)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.14.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (9.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.2)\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.23.26)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.4.0,>=0.3.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.3.9)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.8.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.16.0)\n",
      "Collecting pydantic>=1.10 (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index)\n",
      "  Obtaining dependency information for pydantic>=1.10 from https://files.pythonhosted.org/packages/e5/f3/8296f550276194a58c5500d55b19a27ae0a5a3a51ffef66710c58544b32d/pydantic-2.6.4-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.4)\n",
      "Requirement already satisfied: idna in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.9.0)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.23.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.16.0)\n",
      "Using cached pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.8.2\n",
      "    Uninstalling pydantic-1.8.2:\n",
      "      Successfully uninstalled pydantic-1.8.2\n",
      "Successfully installed pydantic-2.6.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.6.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9977636e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-together in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (0.1.3)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-llms-together) (0.10.20.post2)\n",
      "Requirement already satisfied: llama-index-llms-openai-like<0.2.0,>=0.1.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-llms-together) (0.1.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2024.3.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (0.25.2)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.14.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (9.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (0.9.0)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-together) (0.1.12)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-together) (4.38.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.8.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2.6.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.0.4)\n",
      "Requirement already satisfied: idna in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (3.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-together) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-together) (0.21.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-together) (23.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-together) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-together) (0.4.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (3.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-together) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b0eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, get_response_synthesizer\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e83f009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from python-docx) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sumanyu.p\\appdata\\local\\anaconda3\\lib\\site-packages (from python-docx) (4.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ce8def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_titles=[\"output_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c3bf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted from the document and saved to output_text.txt\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "def extract_text_from_docx(docx_file_path):\n",
    "    # Load the document\n",
    "    doc = Document(docx_file_path)\n",
    "\n",
    "    # Initialize an empty string to store the extracted text\n",
    "    text = ''\n",
    "\n",
    "    # Iterate over each paragraph in the document and extract text\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text += paragraph.text + '\\n'\n",
    "\n",
    "    return text\n",
    "\n",
    "def save_text_to_txt(text, txt_file_path):\n",
    "    # Save the extracted text to a .txt file\n",
    "    with open(txt_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "# Path to the document file\n",
    "docx_file_path = 'New User Adoption Execution Steps.docx'\n",
    "\n",
    "# Path to the .txt file where you want to store the extracted text\n",
    "txt_file_path = 'output_text.txt'\n",
    "\n",
    "# Extract text from the document\n",
    "extracted_text = extract_text_from_docx(docx_file_path)\n",
    "\n",
    "# Save the extracted text to a .txt file\n",
    "save_text_to_txt(extracted_text, txt_file_path)\n",
    "\n",
    "print(\"Text extracted from the document and saved to\", txt_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c7362e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load  documents\n",
    "# city_docs = []\n",
    "# for wiki_title in wiki_titles:\n",
    "#     docs = SimpleDirectoryReader(\n",
    "#         input_files=[f\"./{wiki_title}.docx\"]\n",
    "#     ).load_data()\n",
    "#     docs[0].doc_id = wiki_title\n",
    "#     city_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a966ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceSplitter(chunk_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbc4bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ca9992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff1d1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import Together\n",
    "splitter = SentenceSplitter(chunk_size=1000)\n",
    "llm= Together(\n",
    "        model=\"togethercomputer/llama-2-70b-chat\",\n",
    "        # model=\"gpt-4\",\n",
    "        temperature=0.1,\n",
    "#         max_tokens=207,\n",
    "        top_k=1,\n",
    "        together_api_key=\"1cecf43792b1187b044ab0293853353cc45caf8fdfe0a82e049d53cbf5954d26\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40f7bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.together import TogetherEmbedding\n",
    "\n",
    "embed_model = TogetherEmbedding(\n",
    "    model_name=\"togethercomputer/m2-bert-80M-8k-retrieval\", api_key=\"1cecf43792b1187b044ab0293853353cc45caf8fdfe0a82e049d53cbf5954d26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fa548f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "Settings.context_window = 3000\n",
    "Settings.llm =llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39fadd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm =llm\n",
    "# from llama_index.core import Settings\n",
    "# Settings.context_window = 4096\n",
    "# Settings.llm =llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99fa6da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfced53796cc42d08b020bd57d8ffa03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa6ceb576c3461593909b71d9eaef20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing documents:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: output_text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumanyu.p\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa94bd67014439f805ad59d93bc764f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_summary_index = DocumentSummaryIndex.from_documents(\n",
    "    city_docs,\n",
    "    llm=llm,\n",
    "    transformations=[splitter],\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62765f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe provided text is about the user adoption execution steps for the sales Genie dashboard in the last one week. It includes the steps to refresh the dashboard, take backups for all three dashboards from Tableau, and download data in excel for all six regions. It also includes the steps to filter the data according to created at local date and time in SQL, import data into the test environment, and check for null Comex IT flags and get user details.\\n\\nThis text can answer questions such as:\\n\\n1. What are the steps involved in refreshing the sales Genie dashboard?\\n2. How do you take backups for all three dashboards from Tableau?\\n3. How do you download data in excel for all six regions?\\n4. How do you filter data according to created at local date and time in SQL?\\n5. How do you import data into the test environment?\\n6. How do you check for null Comex IT flags and get user details?\\n7. What are the regions included in the sales Genie dashboard?\\n8. What is the purpose of the user adoption dashboard?\\n9. Where is the user adoption dashboard located?\\n10. What are the different Genie User Adoption dashboards available?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_summary_index.get_document_summary(\"output_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99239b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_summary_index.storage_context.persist(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f72eb71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"index\")\n",
    "doc_summary_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3e87fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = doc_summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdb3e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import ChatPromptTemplate\n",
    "from llama_index.core.llms import ChatMessage,MessageRole\n",
    "\n",
    "chat_text_qa_msgs = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=(\n",
    "            \"Summarize the documents.\\n\"\n",
    "             \"Always answer the query using the provided context information, \"\n",
    "            \n",
    "\n",
    "        ),\n",
    "    ), \n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=(\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information , \"\n",
    "    \"answer the question: {query_str} in bullet points or numbered list where appropriate.\\n\"\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "text_qa_template = ChatPromptTemplate(chat_text_qa_msgs)\n",
    "query=\"\"\"please summarize the documents\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8965e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response__1 = doc_summary_index.as_query_engine(text_qa_template=text_qa_template).query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16d0e2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, here's a summary of the document in bullet points:\n",
      "\n",
      "• User adoption is used to check how many users have used the sales Genie Dashboard in the last one week.\n",
      "\n",
      "• To refresh the dashboard, take backups of all three dashboards from Tableau and update the data in excel for all six regions.\n",
      "\n",
      "• After downloading the data, open the excel sheet, delete the first column, and add two columns (Country & function) in each region.\n",
      "\n",
      "• Filter the data according to created_at_local in SQL.\n",
      "\n",
      "• Take a filtered data in excel and copy that data in a new excel sheet and save it.\n",
      "\n",
      "• Open a remote desktop connection, go to SSMS, copy all excels, and paste them in the Bang Account remote desktop.\n",
      "\n",
      "• Connect to the test environment, select the database (APACBI_FIGO_SALES), right-click, select Task, Import data, and choose a data source window.\n",
      "\n",
      "• Select Data source as Micro soft excel, browse your excel sheet (single sheet at a time), click Next, and choose a Destination window.\n",
      "\n",
      "• Select data base (SQL Server Native client 11.0), check for server name it should be Test Environment, click Next, and select destination as per region.\n",
      "\n",
      "• Select Source Tables and Views Window, select destination as per region, and click Ok.\n",
      "\n",
      "• Check the users with NULL Comex IT Flag and get the user details as per the FIGO_SALES.ALL_SALES_GENIE_USERS format.\n",
      "\n",
      "• Fill in below columns as desired and run below Stored Procedures.\n",
      "\n",
      "• Refresh below Dashboards and the user adoption dashboard is in QA server.\n",
      "\n",
      "I hope this summary helps! Let me know if you have any further questions.\n"
     ]
    }
   ],
   "source": [
    "print(response__1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05b43dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1=\"What are User Adoption Execution Steps? Summarize.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "526b96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response__1 = doc_summary_index.as_query_engine(text_qa_template=text_qa_template).query(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c06e7316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! Here are the User Adoption Execution Steps:\n",
      "\n",
      "1. Take backups for all 3 dashboards from Tableau.\n",
      "2. Connect to test database in SQL.\n",
      "3. Take backups for all tables from the database.\n",
      "4. Download data in excel for all 6 regions.\n",
      "5. Open the excel sheet and delete the first column.\n",
      "6. Add two columns (Country & function) in each region.\n",
      "7. Remove 1 or 2 next to the QARA Dashboard in the NPI column.\n",
      "8. Check for data created at local date and time.\n",
      "9. Filter the data according to created_at_local in SQL.\n",
      "10. Take a filtered data in excel and copy that data in a new excel sheet and save it.\n",
      "11. Open the remote desktop connection, go to SSMS, copy all excels, and paste them in the Bang Account remote desktop.\n",
      "12. Go to SSMS, connect to the Test Environment, select Database (APACBI_FIGO_SALES), right-click, select Task, import data.\n",
      "13. Choose a data source window, select Data source as Micro soft excel, browse your excel sheet (single sheet at a time), click Next.\n",
      "14. Choose a Destination Window, select data base (SQL Server Native client 11.0), check for server name it should be Test Environment, click Next.\n",
      "15. Select destination as per region (Japan / Korea:–[FIGO_SALES][korea_japan_usage], ANZ /TH/SGMY:-dbo.APAC_USAGE_HIST_SNAPSHOT_ALL_QTR, NPI :–[FIGO_SALES][NPI_GENIE_Usage).\n",
      "16. Click Next, Column Mappings Window will appear. Check whether all the columns are mapped correctly, click Ok.\n",
      "17. The window will appear, giving details of success rows.\n",
      "18. Check the users with NULL Comex IT Flag.\n",
      "19. Get the user details as per the FIGO_SALES.ALL_SALES_GENIE_USERS format.\n",
      "20. Fill in below columns as desired.\n",
      "21. Run below Stored Procedures (ANZ/SGMY/TH: dbo.APAC_Usage_Sales_Genie, KR/JP: dbo.APAC_Usage_Sales_Genie_k, NPI:dbo.APAC_Usage_NPI_Genie).\n",
      "22. Refresh below Dashboards (ANZ/SGMY/TH: Sales_Genie-> Sales Genie user analytics, KR/JP: Sales_Genie-> Sales Genie user analytics(JP_KR), NPI: NPI_Genie-> NPI Genie User Anlaytics).\n",
      "\n",
      "That's it! These are the User Adoption Execution Steps.\n"
     ]
    }
   ],
   "source": [
    "print(response__1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f071705",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2=\"Which link I have to use for taking backup of dashboard?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b568ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response__2 = doc_summary_index.as_query_engine(text_qa_template=text_qa_template).query(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adb99785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "* Use the link <https://tableau-qa.medtronic.com/#/site/APACBI> to access the QA server.\n",
      "* Click on the \"Sales Genie\" tab.\n",
      "* Select the \"Sales Genie user analytics\" option for ANZ/SGMY/TH, \"Sales Genie user analytics(JP_KR)\" for KR/JP, and \"NPI Genie User Anlaytics\" for NPI.\n",
      "* Click on the \"Download\" button to download the data in excel for all 6 regions.\n",
      "* Use the link <https://tableau.medtronic.com/#/views/TableauUsageDetails_16226544435390/TraffictoViews?:iid=1> to download the data in excel for all 6 regions.\n",
      "\n",
      "Please note that the provided links are for reference purposes only and may not be accessible outside of the Medtronic network.\n"
     ]
    }
   ],
   "source": [
    "print(response__2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "072245c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3=\" Provide me details of “MDT Network Ids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "325d36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response__3 = doc_summary_index.as_query_engine(text_qa_template=text_qa_template).query(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8595bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, here are the details of \"MDT Network Ids\" in bullet points:\n",
      "\n",
      "* MDT Network Ids are used to identify and manage user adoption in the sales Genie Dashboard.\n",
      "* The Ids are created and managed by the Medtronic IT team.\n",
      "* There are four MDT Network Ids for different regions: ANZ/SGMY/TH, KR/JP, NPI, and Japan/Korea.\n",
      "* Each Id has a unique name and description, such as \"ANZ/SGMY/TH - Sales Genie User Analytics\" and \"KR/JP - Sales Genie User Analytics (JP_KR)\".\n",
      "* The Ids are used to filter and analyze user adoption data in the sales Genie Dashboard.\n",
      "* The data is refreshed every Friday in QA, and the MDT Network Ids are used to identify and update the data for each region.\n",
      "* The updated data is then loaded into the FIGO_SALES.ALL_SALES_GENIE_USERS table.\n",
      "* The MDT Network Ids are also used to run stored procedures, such as dbo.APAC_Usage_Sales_Genie, to update the Comex IT flag for users.\n",
      "* The flag is updated based on the user's country and region.\n",
      "* The updated flag is then reflected in the sales Genie Dashboard for each region.\n",
      "* The MDT Network Ids are also used to refresh the dashboards for each region.\n",
      "* The refreshed dashboards provide up-to-date user adoption data for each region.\n",
      "\n",
      "I hope this helps! Let me know if you have any further questions.\n"
     ]
    }
   ],
   "source": [
    "print(response__3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e556bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.document_summary import (\n",
    "    DocumentSummaryIndexLLMRetriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01fcc3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = DocumentSummaryIndexLLMRetriever(\n",
    "    doc_summary_index,\n",
    "#     choice_select_prompt=None,\n",
    "#     choice_batch_size=3,\n",
    "    choice_top_k=1,\n",
    "#     format_node_batch_fn=None,\n",
    "#     parse_choice_select_answer_fn=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85587c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = retriever.retrieve(\" How do you download data in excel for all six regions?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7248b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(retrieved_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab46384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "User Adoption Execution Steps\r\n",
      "User adoption is used to check how many users have used the sales Genie Dashboard in the last one week. This dashboard is updated every Friday in QA, below are the following steps to refresh this Dashboard: -\r\n",
      "First take backups for all the 3 dashboards from Tableau \r\n",
      "Dashboards:\r\n",
      "For taking backup of dashboard use below link:\r\n",
      "https://tableau-qa.medtronic.com/#/site/APACBI\r\n",
      "ANZ/SGMY/TH: Sales Genie-> Sales Genie user analytics\r\n",
      "KR/JP: Sales Genie-> Sales Genie user analytics(JP_KR)\r\n",
      "NPI: NPI_Genie-> NPI Genie User Anlaytics\r\n",
      "We need to connect to test database in sql.\r\n",
      "Take backups for all table from database\r\n",
      "For ANZ/SGMY/TH use below two queries to take a backup \r\n",
      "Select * into ALL_SALES_GENIE_USERS_11_Jan_2024_BKP from [FIGO_SALES].[ALL_SALES_GENIE_USERS] ;  \r\n",
      "Select * into dbo.APAC_USAGE_HIST_SNAPSHOT_ALL_QTR _11_Jan_2024_BKP  from dbo.APAC_USAGE_HIST_SNAPSHOT_ALL_QTR;\r\n",
      "KR/JP use below two queries to take a backup\r\n",
      "Select * into ALL_SALES_GENIE_USERS_11_Jan_2024_BKP from [FIGO_SALES].[ALL_SALES_GENIE_USERS] ;\r\n",
      "Select * korea_japan_usage_11_Jan_2024_BKP  from  FIGO_SALES.korea_japan_usage;\r\n",
      "NPI: FIGO_SALES.NPI_GENIE_usage\r\n",
      "\r\n",
      "Use the below link to download the data in excel for all 6 regions\r\n",
      "https://tableau.medtronic.com/#/views/TableauUsageDetails_16226544435390/TraffictoViews?:iid=1\r\n",
      "   After downloading, open the excel sheet. In that, delete the first column and before  Column  ‘K’ add two colums(Country & function) in each region.\r\n",
      "ANZ/TH/SGMY/KR/JP \r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "NPI \t\r\n",
      "There is column (Name hist view) need to remove 1 or 2 next to the QARA Dashboard\r\n",
      "\r\n",
      "\r\n",
      "Change column N in excel Action by Action2 in all regions \r\n",
      "We need to check for the data created at local date and time by using below query:\r\n",
      "select * from dbo.APAC_USAGE_HIST_SNAPSHOT_ALL_QTR where Country='ANZ'  \r\n",
      " order by  convert(datetime,created_at_local) desc  \r\n",
      "Note : select Country as per the region.\r\n",
      "For reference below screenshot is attached \r\n",
      "\r\n",
      "\r\n",
      "After checking for data created at local date and time then in excel sheet we need to filter the data according to created_at_local in sql.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Then we need to take a filtered data in excel and copy that data in new excel sheet and save it. \r\n",
      "After preparing the excel sheets for all regions open the remote desktop connection Go to à SSMS àCopy all excels and paste in Bang Account remote desktop. Go to SSMS à Connect to Test Environment.\r\n",
      "Select Database ( APACBI_FIGO_SALES)  à Right click àSelect Task  à Import data\r\n",
      "\r\n",
      "By clicking on import data, choose a data source window will appear as shown below.\r\n",
      "Select Data source as Micro soft excel àBrowse your excel sheet (single sheet at a time) àclick Next\r\n",
      "\r\n",
      "By clicking Next Choose a Destination Window will appear as shown below.\r\n",
      "Select data base (SQL Server Native client 11.0)  à Check for server name it should be Test Environment àClick Next\r\n",
      "\r\n",
      "\r\n",
      "By Clicking Next Source Tables and Views Window will appear as shown below\r\n",
      "à Select destination as per region () \r\n",
      "Japan / Korea:–[FIGO_SALES][korea_japan_usage]\r\n",
      "ANZ /TH/SGMY:-dbo.APAC_USAGE_HIST_SNAPSHOT_ALL_QTR\r\n",
      "NPI :–[FIGO_SALES][NPI_GENIE_Usage\r\n",
      "\r\n",
      "\r\n",
      "By Clicking Next  à Column Mappings Window will appear as shown below. Here we need to check whether all the columns are mapped correctly  à click Ok.\r\n",
      "\r\n",
      "By Clicking Ok à  The window will appear as shown below.  This window will give the details of success rows.\r\n",
      "\r\n",
      "Now data is fully loaded\r\n",
      "1) Check the users with NULL Comex IT Flag \r\n",
      "select distinct SYSTEM_USERS_NAME, [Flag], Country from [APACBI_FGO_SALES].FIGO_SALES.Sales_Genie_User_Analytics where Flag is null and  Country = ‘Japan’;\r\n",
      "Note : select Country as per the region.\r\n",
      " 2) Get the user details  as per the FIGO_SALES.ALL_SALES_GENIE_USERS format.\r\n",
      " 2.1 Username & user id with below query.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_nodes[0].score)\n",
    "print(retrieved_nodes[0].node.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "401260db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use retriever as part of a query engine\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"tree_summarize\")\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "550a6855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The document describes the process for refreshing the user adoption dashboard in QA for various regions such as ANZ, SGMY, TH, KR, JP, and NPI. The steps include taking backups of dashboards from Tableau, connecting to test databases, taking backups of tables, downloading data in excel, filtering data based on created date and time, and importing data into SQL server. Additionally, it mentions checking for NULL Comex IT flags and updating user details in the FIGO_SALES.ALL_SALES_GENIE_USERS table. Finally, it lists the stored procedures to run and dashboards to refresh for each region.\n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "response = query_engine.query(\"summarize the document?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0cf395e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Response\n"
     ]
    }
   ],
   "source": [
    "response__11 = query_engine.query(\"what is effective tax rate?\")\n",
    "print(response__11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fca48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response__11 = query_engine.query(\"what is effective tax rate?\")\n",
    "print(response__11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
